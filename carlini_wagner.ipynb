{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CARLINI WAGNER #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ricordati di cambiare le cartelle del test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Import* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cassd\\miniconda3\\envs\\ai4cyber\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import torch.nn as nn\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "# Import all L-distance based attacks\n",
    "from art.attacks.evasion import CarliniL2Method, CarliniL0Method, CarliniLInfMethod\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import Inception.Inception\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if str(device) in 'cuda':\n",
    "    print(\"Import Inception.Inception\")\n",
    "    import inception\n",
    "elif str(device) == \"cpu\":\n",
    "    print(\"Import Facenet.Inception\")\n",
    "    from facenet_pytorch import InceptionResnetV1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inizializzazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = inception.InceptionResnetV1(pretrained='vggface2').eval()\n",
    "resnet.classify = True\n",
    "resnet.to(device)\n",
    "fpath = tf.keras.utils.get_file('rcmalli_vggface_labels_v2.npy',\n",
    "                             \"https://github.com/rcmalli/keras-vggface/releases/download/v2.0/rcmalli_vggface_labels_v2.npy\",\n",
    "                             cache_subdir=\"./\")\n",
    "LABELS = np.load(fpath)\n",
    "\n",
    "def load_image(filename):\n",
    "    img = Image.open(filename)\n",
    "    rsz = img.resize((160, 160))\n",
    "    tns = transforms.ToTensor()(rsz)\n",
    "    tns.to(device)\n",
    "    return tns\n",
    "\n",
    "classifier = PyTorchClassifier(resnet,input_shape=[224,224], loss=CrossEntropyLoss(),nb_classes=8631, device_type=device) #This class implements a classifier with the PyTorch framework.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SIGNIFICATO PARAMETRI \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il metodo Carlini and Wagner L_0 Attack è un attacco iterativo che mira a trovare un esempio avversario minimizzando il numero di caratteristiche modificate (norma L_0). Ecco una spiegazione dettagliata del metodo e dei suoi parametri:\n",
    "\n",
    "Metodo Carlini and Wagner L_0 Attack\n",
    "Parametri del Metodo __init__\n",
    "\n",
    "classifier (CLASSIFIER_CLASS_LOSS_GRADIENTS_TYPE):\n",
    "Un classificatore addestrato che implementa i metodi per calcolare le perdite e i gradienti delle perdite rispetto agli input.\n",
    "\n",
    "confidence (float = 0.0):\n",
    "La fiducia degli esempi avversari: un valore più alto produce esempi che sono più lontani dall'input originale ma classificati con maggiore fiducia come la classe target. Questo parametro bilancia la necessità di modificare l'input originale con la certezza che l'output sia nella classe avversaria desiderata.\n",
    "\n",
    "targeted (bool = False):\n",
    "Indica se l'attacco è mirato a una specifica classe (True) o meno (False). In un attacco mirato, l'obiettivo è far classificare l'input avversario come una classe specifica scelta dall'attaccante. In un attacco non mirato, l'obiettivo è semplicemente far classificare l'input in una classe diversa da quella corretta.\n",
    "\n",
    "learning_rate (float = 0.01):\n",
    "Il tasso di apprendimento iniziale per l'algoritmo di attacco. Valori più piccoli producono risultati migliori ma convergono più lentamente.\n",
    "\n",
    "binary_search_steps (int = 10):\n",
    "Numero di volte in cui regolare la costante con la ricerca binaria (valore positivo). Se binary_search_steps è grande, l'algoritmo non è molto sensibile al valore di initial_const. Questo parametro controlla quante volte la costante di trade-off viene aggiustata per trovare il miglior equilibrio tra la distanza e la fiducia.\n",
    "\n",
    "max_iter (int = 10):\n",
    "Il numero massimo di iterazioni per l'attacco.\n",
    "\n",
    "initial_const (float = 0.01):\n",
    "La costante di trade-off iniziale c per regolare l'importanza relativa tra la distanza e la fiducia. Se binary_search_steps è grande, il valore iniziale di questa costante non è critico.\n",
    "\n",
    "mask (ndarray | None = None):\n",
    "Le caratteristiche iniziali che possono essere modificate dall'algoritmo. Se non specificato, l'algoritmo utilizza l'intero set di caratteristiche. Questo parametro può essere utilizzato per limitare l'attacco a modificare solo determinate parti dell'input.\n",
    "\n",
    "warm_start (bool = True):\n",
    "Invece di iniziare la discesa del gradiente in ogni iterazione dall'immagine iniziale, si inizia la discesa del gradiente dalla soluzione trovata nell'iterazione precedente. Questo parametro può accelerare la convergenza.\n",
    "\n",
    "max_halving (int = 5):\n",
    "Numero massimo di passi di dimezzamento nella ricerca lineare di ottimizzazione. Questo parametro controlla quante volte la dimensione del passo viene dimezzata durante la ricerca di un passo ottimale.\n",
    "\n",
    "max_doubling (int = 5):\n",
    "Numero massimo di passi di raddoppiamento nella ricerca lineare di ottimizzazione. Questo parametro controlla quante volte la dimensione del passo viene raddoppiata durante la ricerca di un passo ottimale.\n",
    "batch_size (int = 1):\n",
    "\n",
    "La dimensione del batch su cui vengono generati i campioni avversari. Questo parametro determina quanti campioni vengono processati contemporaneamente durante l'attacco.\n",
    "\n",
    "verbose (bool = True):\n",
    "Mostra barre di avanzamento. Se impostato su True, verranno visualizzati i progressi dell'attacco durante l'esecuzione."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Attacco* **NON TARGETED**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"test_set_cropped_piccolo/\" \n",
    "binary_search_steps = 1\n",
    "confidence = 0.8\n",
    "max_iter = [1]\n",
    "learning_rate = [0.1,0.2,0.5,0.7,0.9]\n",
    "initial_const = [1,300,700]\n",
    "\n",
    "accuracy_for_eps = []\n",
    "accuracy_for_max_iter = []\n",
    "perturbation_for_eps = []\n",
    "perturbation_for_max_iter = []\n",
    "correct_predictions = 0\n",
    "total_images = 0\n",
    "accuracy_for_learning_rate = np.zeros((len(initial_const),len(learning_rate)))        #riga\n",
    "perturbation_for_learning_rate = np.zeros((len(initial_const),len(learning_rate)))\n",
    "print(\"Inizio Attacco CARLINI-WAGNER NON-TARGETED\")\n",
    "learning_contatore = 0\n",
    "\n",
    "for i in range(len(initial_const)):\n",
    "        for learning in learning_rate:   #Se qualcosa funziona strano controllare questo zip\n",
    "            correct_predictions = 0\n",
    "            total_images = 0\n",
    "            perturbation = []\n",
    "            \n",
    "            attack = CarliniL2Method(classifier=classifier, binary_search_steps=binary_search_steps, confidence=confidence, max_iter=max_iter[0], learning_rate=learning, initial_const=initial_const[i], targeted=False)\n",
    "            \n",
    "            print(\"<---> Attacco con learning rate = {} e initial cost = {} <--->\".format(learning,initial_const[i]))\n",
    "            for filename in os.listdir(dataset_dir):\n",
    "                if filename.endswith(\".jpg\") or filename.endswith(\".jpeg\"):\n",
    "                    person_path = os.path.join(dataset_dir, filename)\n",
    "                    test_img = load_image(person_path)\n",
    "                    test_img = test_img.unsqueeze(0)\n",
    "                    test_img = test_img.numpy()\n",
    "                    test_images_adv = attack.generate(test_img)\n",
    "                    model_predictions = classifier.predict(test_images_adv)\n",
    "                    correct_label = re.sub(r'_\\d+_face_0\\.jpg$', '', filename)   \n",
    "                    perturbation.append(np.mean(np.abs((test_images_adv - test_img))))  #Calcolo la perturbazione applicata su ogni immagine e la salvo in un vettore.\n",
    "                    predicted_label = LABELS[np.array(model_predictions[0].argmax())]\n",
    "                    print(\"Etichetta reale:{} || Predetto: {} con probabilità: {} e con perturbazione: {}\".format(correct_label,predicted_label,model_predictions[0][model_predictions.argmax()],perturbation[-1]))\n",
    "                    total_images+=1\n",
    "                    \n",
    "                    predicted_label = str(predicted_label)\n",
    "\n",
    "                    if correct_label in predicted_label:\n",
    "                        correct_predictions+=1\n",
    "\n",
    "                    accuracy = correct_predictions/total_images\n",
    "                    print(\"Adversarial Sample misclassificati correttamente attuale: {}%\".format((100-(accuracy*100))))  # Calcolo l'accuracy attuale ogni volta che classifico una nuova immagine\n",
    "\n",
    "\n",
    "            if total_images != 0:    \n",
    "                if len(perturbation) == total_images:\n",
    "                    perturbazione_media = sum(perturbation)/total_images   # In media quanta pertubazione è stata applicata su ogni immagine \n",
    "                    perturbation_for_eps.append(perturbazione_media)\n",
    "                    print(\"----------- Perturbazione media aggiunta a tutte le immagini ---> {}% ----------------\".format(learning,perturbazione_media))\n",
    "                    perturbation_for_learning_rate[i][learning_contatore] = perturbazione_media \n",
    "                      \n",
    "                final_accuracy = correct_predictions/total_images          # Accuracy su tutte le immagini\n",
    "                accuracy_for_eps.append(final_accuracy)\n",
    "                print(\"----------- Accuracy sugli adversarial Sample equivale a ---> {}% ----------------\".format(learning,final_accuracy))\n",
    "                accuracy_for_learning_rate[i][learning_contatore] = final_accuracy\n",
    "                learning_contatore += 1\n",
    "            else:\n",
    "                print(\"ERRORE TOTAL IMAGE == 0 ERRORE\")\n",
    "                    \n",
    "        learning_contatore = 0\n",
    "        print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------lllllllllllllllllll\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#matrice righe = iterazione, colonne = learning rate\n",
    "print(perturbation_for_learning_rate)\n",
    "print(accuracy_for_learning_rate)\n",
    "print(len(learning_rate))\n",
    "print(len(perturbation_for_learning_rate[0]))\n",
    "learning_rate = [0.1,0.2,0.5,0.7,0.9]\n",
    "print(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plot accuracy/Attack strength\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(learning_rate, perturbation_for_learning_rate[0], 'b-', label='Perturbazione')\n",
    "ax.plot(learning_rate, accuracy_for_learning_rate[0], 'r-', label='Accuracy')\n",
    "#ax.plot(np.array(learning_rate), np.array(perturbation_for_learning_rate[1]), 'r-', label='max_iter == 2')\n",
    "#ax.plot(np.array(learning_rate), np.array(perturbation_for_learning_rate[2]), 'g-.', label='max_iter == 4')\n",
    "\n",
    "legend = ax.legend(loc='upper center', shadow=True, fontsize='large')\n",
    "legend.get_frame().set_facecolor('#00FFCC')\n",
    "\n",
    "plt.ylabel('Perturbation')\n",
    "plt.xlabel('Learning Rate')\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grafico Accuracy media a ogni iterazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# plot accuracy/Attack strength\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(learning_rate, np.array(accuracy_for_learning_rate[0]), 'b--', label='initial cost == 1')\n",
    "ax.plot(learning_rate, np.array(accuracy_for_learning_rate[1]), 'r-', label='initial cost == 300')\n",
    "ax.plot(learning_rate, np.array(accuracy_for_learning_rate[2]), 'g-', label='initial cost == 700')\n",
    "\n",
    "legend = ax.legend(loc='upper center', shadow=True, fontsize='large')\n",
    "legend.get_frame().set_facecolor('#00FFCC')\n",
    "\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Learning Rate')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grafico Accuracy media/Perturbazione media\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(np.array(accuracy_for_max_iter), np.array(perturbation_for_max_iter), 'b--', label='NN1')\n",
    "\n",
    "legend = ax.legend(loc='upper center', shadow=True, fontsize='large')\n",
    "legend.get_frame().set_facecolor('#00FFCC')\n",
    "\n",
    "plt.xlabel('Attack strength (eps)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Attacco* **TARGETED**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETICHETTA TARGET:   Aaron_Hernandez\n",
      "Inizio Attacco CARLINI-WAGNER TARGETED\n",
      "<---> Attacco con learning rate = 0.05 e initial cost = 0.1 <--->\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C&W L_2: 100%|██████████| 1/1 [00:03<00:00,  3.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etichetta reale:Andrea_Pirlo || Predetto:  Andrea_Pirlo con probabilità: 12.725250244140625 e con perturbazione: 0.0\n",
      "Adversarial Sample misclassificati correttamente attualmente: 0.0%\n",
      "Accuracy attuale: 100.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C&W L_2: 100%|██████████| 1/1 [00:03<00:00,  3.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etichetta reale:Antonio_Cassano || Predetto:  Branch_Warren con probabilità: 10.506441116333008 e con perturbazione: 0.0\n",
      "Adversarial Sample misclassificati correttamente attualmente: 0.0%\n",
      "Accuracy attuale: 50.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C&W L_2: 100%|██████████| 1/1 [00:03<00:00,  3.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etichetta reale:Ariana_Grande || Predetto:  Ariana_Grande con probabilità: 11.170966148376465 e con perturbazione: 0.0\n",
      "Adversarial Sample misclassificati correttamente attualmente: 0.0%\n",
      "Accuracy attuale: 66.66666666666666%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C&W L_2: 100%|██████████| 1/1 [00:03<00:00,  3.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etichetta reale:Ashley_Scott || Predetto:  Ashley_Scott con probabilità: 13.896852493286133 e con perturbazione: 0.0\n",
      "Adversarial Sample misclassificati correttamente attualmente: 0.0%\n",
      "Accuracy attuale: 75.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C&W L_2: 100%|██████████| 1/1 [00:02<00:00,  2.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etichetta reale:Boris_Johnson || Predetto:  Boris_Johnson con probabilità: 13.323941230773926 e con perturbazione: 0.0\n",
      "Adversarial Sample misclassificati correttamente attualmente: 0.0%\n",
      "Accuracy attuale: 80.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C&W L_2: 100%|██████████| 1/1 [00:02<00:00,  2.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etichetta reale:Brad_Pitt || Predetto:  Brad_Pitt con probabilità: 13.206241607666016 e con perturbazione: 0.0\n",
      "Adversarial Sample misclassificati correttamente attualmente: 0.0%\n",
      "Accuracy attuale: 83.33333333333334%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C&W L_2: 100%|██████████| 1/1 [00:03<00:00,  3.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etichetta reale:Christian_De_Sica || Predetto:  Christian_De_Sica con probabilità: 13.7531156539917 e con perturbazione: 0.0\n",
      "Adversarial Sample misclassificati correttamente attualmente: 0.0%\n",
      "Accuracy attuale: 85.71428571428571%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C&W L_2: 100%|██████████| 1/1 [00:02<00:00,  2.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etichetta reale:Christopher_Nolan || Predetto:  Christopher_Nolan con probabilità: 12.074438095092773 e con perturbazione: 0.0\n",
      "Adversarial Sample misclassificati correttamente attualmente: 0.0%\n",
      "Accuracy attuale: 87.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C&W L_2: 100%|██████████| 1/1 [00:02<00:00,  2.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etichetta reale:Cristiano_Ronaldo || Predetto:  Cristiano_Ronaldo con probabilità: 12.945646286010742 e con perturbazione: 0.0\n",
      "Adversarial Sample misclassificati correttamente attualmente: 0.0%\n",
      "Accuracy attuale: 88.88888888888889%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C&W L_2: 100%|██████████| 1/1 [00:02<00:00,  2.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etichetta reale:Diego_Maradona || Predetto:  Diego_Maradona con probabilità: 12.622477531433105 e con perturbazione: 0.0\n",
      "Adversarial Sample misclassificati correttamente attualmente: 0.0%\n",
      "Accuracy attuale: 90.0%\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'learning' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 72\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(perturbation) \u001b[38;5;241m==\u001b[39m total_images:\n\u001b[0;32m     71\u001b[0m     perturbazione_media \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(perturbation)\u001b[38;5;241m/\u001b[39mtotal_images    \n\u001b[1;32m---> 72\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m----------- Perturbazione media aggiunta a tutte le immagini per learning: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m equivale a \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m ----------------\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[43mlearning\u001b[49m,perturbazione_media))\n\u001b[0;32m     73\u001b[0m     perturbation_for_learning_rate_targeted[z][i][j] \u001b[38;5;241m=\u001b[39m perturbazione_media\n\u001b[0;32m     75\u001b[0m final_accuracy \u001b[38;5;241m=\u001b[39m correct_predictions\u001b[38;5;241m/\u001b[39mtotal_images\n",
      "\u001b[1;31mNameError\u001b[0m: name 'learning' is not defined"
     ]
    }
   ],
   "source": [
    "dataset_dir = \"test_set_cropped_piccolo/\" \n",
    "binary_search_steps = 3\n",
    "confidence = 0.7\n",
    "max_iter = [2,4]\n",
    "learning_rate = [0.05,0.1,0.3,0.5,1]\n",
    "initial_const = [0.1,1,150,300,400]\n",
    "\n",
    "accuracy_misclassified_for_eps = []\n",
    "accuracy_misclassified_for_max_iter = []\n",
    "accuracy_for_eps = []\n",
    "accuracy_for_max_iter = []\n",
    "perturbation_for_eps = []\n",
    "perturbation_for_max_iter = []\n",
    "correct_misclassified = 0\n",
    "total_images = 0\n",
    "\n",
    "accuracy_for_learning_rate_targeted = np.zeros((len(max_iter),len(initial_const),len(learning_rate)))        #riga-colonna\n",
    "perturbation_for_learning_rate_targeted = np.zeros((len(initial_const),len(learning_rate)))\n",
    "accuracy_misclassified_for_learning_rate = np.zeros((len(initial_const),len(learning_rate)))\n",
    "\n",
    "target_class = 10\n",
    "etichetta_target = LABELS[target_class]\n",
    "print(\"ETICHETTA TARGET: \", etichetta_target)\n",
    "\n",
    "targeted_labels = target_class*np.ones(LABELS.size)\n",
    "one_hot_targeted_labels = tf.keras.utils.to_categorical(targeted_labels, num_classes = 8631)\n",
    "\n",
    "\n",
    "learning_contatore = 0\n",
    "print(\"Inizio Attacco CARLINI-WAGNER TARGETED\")\n",
    "for z in range(len(max_iter)):\n",
    "    for i in range(len(initial_const)):\n",
    "            for j in range(len(learning_rate)):   #Se qualcosa funziona strano controllare questo zip\n",
    "                correct_predictions = 0\n",
    "                correct_misclassified = 0\n",
    "                total_images = 0\n",
    "                perturbation = []\n",
    "                \n",
    "                attack = CarliniL2Method(classifier=classifier, binary_search_steps=binary_search_steps, confidence=confidence, max_iter=max_iter[z], learning_rate=learning_rate[j], initial_const=initial_const[i], targeted=True)\n",
    "                \n",
    "                print(\"<---> Attacco con learning rate = {} e initial cost = {} <--->\".format(learning_rate[j],initial_const[i]))\n",
    "                for filename in os.listdir(dataset_dir):\n",
    "                    if filename.endswith(\".jpg\") or filename.endswith(\".jpeg\"):\n",
    "                        person_path = os.path.join(dataset_dir, filename)\n",
    "                        test_img = load_image(person_path)\n",
    "                        test_img = test_img.unsqueeze(0)\n",
    "                        test_img = test_img.numpy()\n",
    "                        test_images_adv = attack.generate(test_img, one_hot_targeted_labels)\n",
    "                        model_predictions = classifier.predict(test_images_adv)\n",
    "                        correct_label = re.sub(r'_\\d+_face_0\\.jpg$', '', filename)   \n",
    "                        perturbation.append(np.mean(np.abs((test_images_adv - test_img))))  \n",
    "                        predicted_label = LABELS[np.array(model_predictions[0].argmax())]\n",
    "                        print(\"Etichetta reale:{} || Predetto: {} con probabilità: {} e con perturbazione: {}\".format(correct_label,predicted_label,model_predictions[0][model_predictions.argmax()],perturbation[-1]))\n",
    "                        total_images+=1\n",
    "                        \n",
    "                        predicted_label = str(predicted_label)\n",
    "\n",
    "                        if correct_label in predicted_label:\n",
    "                            correct_predictions+=1\n",
    "                            \n",
    "                        if etichetta_target in predicted_label:  \n",
    "                            correct_misclassified = correct_misclassified+1   #Se il modello predice l'etichetta target allora è correttamente misclassificato\n",
    "\n",
    "                        accuracy_misclassified = correct_misclassified/total_images\n",
    "                        print(\"Adversarial Sample misclassificati correttamente attualmente: {}%\".format((accuracy_misclassified)))\n",
    "                        print(\"Accuracy attuale: {}%\".format((correct_predictions/total_images)*100))\n",
    "                \n",
    "\n",
    "                if total_images != 0:    \n",
    "                    if len(perturbation) == total_images:\n",
    "                        perturbazione_media = sum(perturbation)/total_images    \n",
    "                        print(\"----------- Perturbazione media aggiunta a tutte le immagini per learning: {} equivale a {}% ----------------\".format(learning_rate[j],perturbazione_media))\n",
    "                        perturbation_for_learning_rate_targeted[z][i][j] = perturbazione_media\n",
    "\n",
    "                    final_accuracy = correct_predictions/total_images\n",
    "                    print(\"----------- Accuracy sugli adversarial Sample per learning: {} equivale a {}% ----------------\".format(learning_rate[j],final_accuracy))\n",
    "                    accuracy_for_learning_rate_targeted[z][i][j] = final_accuracy\n",
    "\n",
    "                    accuracy_misclassified = correct_misclassified/total_images\n",
    "                    accuracy_misclassified_for_learning_rate[z][i][j] = accuracy_misclassified\n",
    "                    print(\"----------- Adversarial Sample misclassificati correttamente: {}% -----------\".format((accuracy_misclassified)))\n",
    "        \n",
    "\n",
    "            print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Matrice Accuracy' + str(learning_rate))\n",
    "for row_name, row_data in zip(initial_const, accuracy_for_learning_rate_targeted):\n",
    "    print(f'        {row_name }   ' + '  '.join(map(str, row_data)))\n",
    "\n",
    "\n",
    "print('Matrice Perturbation' + str(learning_rate))\n",
    "for row_name, row_data in zip(initial_const, perturbation_for_learning_rate_targeted):\n",
    "    print(f'        {row_name}         ' + '  '.join(map(str, row_data)))\n",
    "\n",
    "\n",
    "print('Matrice Misclassificazione' + str(learning_rate))\n",
    "for row_name, row_data in zip(initial_const, accuracy_misclassified_for_learning_rate):\n",
    "    print(f'        {row_name}         ' + '  '.join(map(str, row_data)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot accuracy/Attack strength\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(learning_rate, perturbation_for_learning_rate_targeted[0], 'b-', label='Perturbazione')\n",
    "ax.plot(learning_rate, accuracy_for_learning_rate_targeted[0], 'r-', label='Accuracy')\n",
    "#ax.plot(np.array(learning_rate), np.array(perturbation_for_learning_rate[1]), 'r-', label='max_iter == 2')\n",
    "#ax.plot(np.array(learning_rate), np.array(perturbation_for_learning_rate[2]), 'g-.', label='max_iter == 4')\n",
    "\n",
    "legend = ax.legend(loc='upper center', shadow=True, fontsize='large')\n",
    "legend.get_frame().set_facecolor('#00FFCC')\n",
    "\n",
    "plt.ylabel('Perturbation')\n",
    "plt.xlabel('Learning Rate')\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(test_img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Caricamento di una sola immagine per i test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"test_set_cropped/Brad_Pitt_1_face_0.jpg\"\n",
    "test_img = load_image(filename)\n",
    "\n",
    "print(test_img.shape)\n",
    "print(test_img.size)\n",
    "test_img = test_img.unsqueeze(0)\n",
    "print(test_img.shape)\n",
    "print(test_img.size)\n",
    "test_img = test_img.numpy()\n",
    "print(test_img.shape)\n",
    "print(type(test_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_search_steps = 5\n",
    "confidence = 0.7\n",
    "max_iter = 7\n",
    "learning_rate = 0.001\n",
    "initial_const = 350\n",
    "\n",
    "target_class = 100\n",
    "etichetta_target = LABELS[target_class]\n",
    "print(\"ETICHETTA TARGET: \", etichetta_target)\n",
    "\n",
    "targeted_labels = target_class*np.ones(LABELS.size)\n",
    "one_hot_targeted_labels = tf.keras.utils.to_categorical(targeted_labels, num_classes = 8631)\n",
    "\n",
    "attack = CarliniL2Method(classifier=classifier, binary_search_steps=binary_search_steps, confidence=confidence, max_iter=max_iter, learning_rate=learning_rate, initial_const=initial_const, targeted=True)\n",
    "test_images_adv = attack.generate(test_img, one_hot_targeted_labels)\n",
    "model_predictions = classifier.predict(test_images_adv)\n",
    "correct_label = re.sub(r'_\\d+_face_0\\.jpg$', '', filename)   \n",
    "perturbation.append(np.mean(np.abs((test_images_adv - test_img))))  \n",
    "predicted_label = LABELS[np.array(model_predictions[0].argmax())]\n",
    "print(\"Etichetta reale:{} || Predetto: {} con probabilità: {} e con perturbazione: {}\".format(correct_label,predicted_label,model_predictions[0][model_predictions.argmax()],perturbation[-1]))\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepara le immagini per la visualizzazione\n",
    "# Rimuovi la dimensione batch extra e converti nel formato channels-last\n",
    "\n",
    "test_images_adv = np.squeeze(test_images_adv, axis=0)\n",
    "test_images_adv = np.transpose(test_images_adv, (1, 2, 0))\n",
    "\n",
    "# Converti le immagini in uint8 per la visualizzazione\n",
    "if test_img.dtype != np.uint8:\n",
    "    test_img_numpy = (test_img * 255).astype(np.uint8)\n",
    "    test_img_numpy = np.squeeze(test_img_numpy, axis=0)  # Rimuovi la dimensione batch extra\n",
    "    test_img_numpy = np.transpose(test_img_numpy, (1, 2, 0))\n",
    "\n",
    "if test_images_adv.dtype != np.uint8:\n",
    "    test_images_adv = (test_images_adv * 255).astype(np.uint8)\n",
    "\n",
    "# Visualizza le immagini affiancate con Matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "# Mostra l'immagine originale\n",
    "ax1.imshow(test_img_numpy)\n",
    "ax1.set_title('Original Image')\n",
    "ax1.axis('off')\n",
    "\n",
    "# Mostra l'immagine avversaria\n",
    "ax2.imshow(test_images_adv)\n",
    "ax2.set_title(f'Adversarial Image\\nPredicted: {predicted_label}')\n",
    "ax2.axis('off')\n",
    "\n",
    "# Mostra la figura\n",
    "plt.suptitle(\"DeepFool Adversarial Images\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "artoolbox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
