{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CARLINI WAGNER #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ricordati di cambiare le cartelle del test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Import* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cassd\\miniconda3\\envs\\ai4cyber\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import torch.nn as nn\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "# Import all L-distance based attacks\n",
    "from art.attacks.evasion import CarliniL2Method, CarliniL0Method, CarliniLInfMethod\n",
    "from RESNET import ResNet\n",
    "from utils import get_labels\n",
    "from utils import load_state_dict\n",
    "from utils import load_image_NN1\n",
    "from utils import load_test_image_NN2\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = str(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import Inception.Inception\n"
     ]
    }
   ],
   "source": [
    "if device in 'cuda':\n",
    "    print(\"Import Inception.Inception\")\n",
    "    import inception\n",
    "    nn1 = inception.InceptionResnetV1(pretrained='vggface2').eval()\n",
    "elif device == \"cpu\":\n",
    "    print(\"Import Facenet.Inception\")\n",
    "    from facenet_pytorch import Inceptionnn1V1\n",
    "    nn1 = InceptionResnetV1(pretrained='vggface2').eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inizializzazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------nn1-----------------------\n",
    "nn1.classify = True\n",
    "nn1.to(device)\n",
    "fpath = tf.keras.utils.get_file('rcmalli_vggface_labels_v2.npy',\n",
    "                             \"https://github.com/rcmalli/keras-vggface/releases/download/v2.0/rcmalli_vggface_labels_v2.npy\",\n",
    "                             cache_subdir=\"./\")\n",
    "model_nn1 = PyTorchClassifier(nn1,input_shape=[224,224], loss=CrossEntropyLoss(),nb_classes=8631, device_type=device) #This class implements a classifier with the PyTorch framework.\n",
    "\n",
    "# ---------------------nn2-----------------------------\n",
    "nn2 = ResNet.resnet50(num_classes=8631, include_top=True)\n",
    "load_state_dict(nn2,'resnet50_scratch_weight.pkl')\n",
    "nn2.eval()\n",
    "nn2.to(device)\n",
    "model_nn2 = PyTorchClassifier(nn2,input_shape=[224,224], loss=CrossEntropyLoss(),nb_classes=8631, device_type=device)\n",
    "\n",
    "#--------------------------------------------------------\n",
    "LABELS = get_labels()\n",
    "\n",
    "def load_image(filename):\n",
    "    img = Image.open(filename)\n",
    "    rsz = img.resize((160, 160))\n",
    "    tns = transforms.ToTensor()(rsz)\n",
    "    tns.to(device)\n",
    "    return tns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SIGNIFICATO PARAMETRI \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il metodo Carlini and Wagner L_0 Attack è un attacco iterativo che mira a trovare un esempio avversario minimizzando il numero di caratteristiche modificate (norma L_0). Ecco una spiegazione dettagliata del metodo e dei suoi parametri:\n",
    "\n",
    "Metodo Carlini and Wagner L_0 Attack\n",
    "Parametri del Metodo __init__\n",
    "\n",
    "classifier (CLASSIFIER_CLASS_LOSS_GRADIENTS_TYPE):\n",
    "Un classificatore addestrato che implementa i metodi per calcolare le perdite e i gradienti delle perdite rispetto agli input.\n",
    "\n",
    "confidence (float = 0.0):\n",
    "La fiducia degli esempi avversari: un valore più alto produce esempi che sono più lontani dall'input originale ma classificati con maggiore fiducia come la classe target. Questo parametro bilancia la necessità di modificare l'input originale con la certezza che l'output sia nella classe avversaria desiderata.\n",
    "\n",
    "targeted (bool = False):\n",
    "Indica se l'attacco è mirato a una specifica classe (True) o meno (False). In un attacco mirato, l'obiettivo è far classificare l'input avversario come una classe specifica scelta dall'attaccante. In un attacco non mirato, l'obiettivo è semplicemente far classificare l'input in una classe diversa da quella corretta.\n",
    "\n",
    "learning_rate (float = 0.01):\n",
    "Il tasso di apprendimento iniziale per l'algoritmo di attacco. Valori più piccoli producono risultati migliori ma convergono più lentamente.\n",
    "\n",
    "binary_search_steps (int = 10):\n",
    "Numero di volte in cui regolare la costante con la ricerca binaria (valore positivo). Se binary_search_steps è grande, l'algoritmo non è molto sensibile al valore di initial_const. Questo parametro controlla quante volte la costante di trade-off viene aggiustata per trovare il miglior equilibrio tra la distanza e la fiducia.\n",
    "\n",
    "max_iter (int = 10):\n",
    "Il numero massimo di iterazioni per l'attacco.\n",
    "\n",
    "initial_const (float = 0.01):\n",
    "La costante di trade-off iniziale c per regolare l'importanza relativa tra la distanza e la fiducia. Se binary_search_steps è grande, il valore iniziale di questa costante non è critico.\n",
    "\n",
    "mask (ndarray | None = None):\n",
    "Le caratteristiche iniziali che possono essere modificate dall'algoritmo. Se non specificato, l'algoritmo utilizza l'intero set di caratteristiche. Questo parametro può essere utilizzato per limitare l'attacco a modificare solo determinate parti dell'input.\n",
    "\n",
    "warm_start (bool = True):\n",
    "Invece di iniziare la discesa del gradiente in ogni iterazione dall'immagine iniziale, si inizia la discesa del gradiente dalla soluzione trovata nell'iterazione precedente. Questo parametro può accelerare la convergenza.\n",
    "\n",
    "max_halving (int = 5):\n",
    "Numero massimo di passi di dimezzamento nella ricerca lineare di ottimizzazione. Questo parametro controlla quante volte la dimensione del passo viene dimezzata durante la ricerca di un passo ottimale.\n",
    "\n",
    "max_doubling (int = 5):\n",
    "Numero massimo di passi di raddoppiamento nella ricerca lineare di ottimizzazione. Questo parametro controlla quante volte la dimensione del passo viene raddoppiata durante la ricerca di un passo ottimale.\n",
    "batch_size (int = 1):\n",
    "\n",
    "La dimensione del batch su cui vengono generati i campioni avversari. Questo parametro determina quanti campioni vengono processati contemporaneamente durante l'attacco.\n",
    "\n",
    "verbose (bool = True):\n",
    "Mostra barre di avanzamento. Se impostato su True, verranno visualizzati i progressi dell'attacco durante l'esecuzione."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Attacco* **NON TARGETED**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inizio Attacco CARLINI-WAGNER NON-TARGETED\n",
      "<---> Attacco con learning rate = 0.05 e initial cost = 300 <--->\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.35s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.18s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.26s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.23s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.20s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.18s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.08s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.12s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.10s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<---> Attacco con learning rate = 0.2 e initial cost = 300 <--->\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.10s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.34s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.44s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.24s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.16s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.27s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.09s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.19s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.22s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<---> Attacco con learning rate = 0.5 e initial cost = 300 <--->\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.32s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.35s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.34s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.34s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.27s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.37s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.26s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.37s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.35s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<---> Attacco con learning rate = 0.7 e initial cost = 300 <--->\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.34s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.38s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.35s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.52s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.34s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.35s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.26s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.38s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.40s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<---> Attacco con learning rate = 1 e initial cost = 300 <--->\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.44s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.34s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.35s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.46s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.43s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.52s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.34s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.27s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.26s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------lllllllllllllllllll\n",
      "\n",
      "<---> Attacco con learning rate = 0.05 e initial cost = 300 <--->\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.08s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.10s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.15s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.11s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.11s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.09s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.11s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.06s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.04s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<---> Attacco con learning rate = 0.2 e initial cost = 300 <--->\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.09s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.34s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.39s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.29s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.17s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.14s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.07s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.17s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.22s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<---> Attacco con learning rate = 0.5 e initial cost = 300 <--->\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.31s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.36s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.45s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.43s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.36s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.42s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.42s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.50s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.39s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<---> Attacco con learning rate = 0.7 e initial cost = 300 <--->\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.32s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.34s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.34s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.45s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.38s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.35s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.28s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.39s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.40s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<---> Attacco con learning rate = 1 e initial cost = 300 <--->\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.40s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.39s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.38s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.48s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.41s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.47s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.32s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.26s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.27s/it]\n",
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------lllllllllllllllllll\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_dir = \"test_set_cropped_piccolo/\" \n",
    "binary_search_steps = 3\n",
    "confidence = 0.5\n",
    "max_iter = [1,5]\n",
    "learning_rate = [0.05,0.2,0.5,0.7,1]\n",
    "initial_const = [500]\n",
    "\n",
    "\n",
    "correct_predictions_nn1 = 0\n",
    "accuracy_for_learning_rate_nn1 = np.zeros((len(max_iter),len(initial_const),len(learning_rate)))        #riga\n",
    "perturbation_for_learning_rate_nn1 = np.zeros((len(max_iter),len(initial_const),len(learning_rate)))\n",
    "\n",
    "correct_predictions_nn2 = 0\n",
    "accuracy_for_learning_rate_nn2 = np.zeros((len(max_iter),len(initial_const),len(learning_rate)))       #riga\n",
    "#perturbation_for_learning_rate_nn2 = np.zeros((len(initial_const),len(learning_rate)))\n",
    "\n",
    "total_images = 0\n",
    "print(\"Inizio Attacco CARLINI-WAGNER NON-TARGETED\")\n",
    "\n",
    "for z in range(len(max_iter)):\n",
    "    for i in range(len(initial_const)):\n",
    "            for j in range(len(learning_rate)):   #Se qualcosa funziona strano controllare questo zip\n",
    "                correct_predictions_nn1 = 0\n",
    "                correct_predictions_nn2 = 0\n",
    "                total_images = 0\n",
    "                perturbation = []\n",
    "                \n",
    "                attack = CarliniL2Method(classifier=model_nn1, binary_search_steps=binary_search_steps, confidence=confidence, max_iter=max_iter[0], learning_rate=learning_rate[j], initial_const=initial_const[i], targeted=False)\n",
    "                \n",
    "                print(\"<---> Attacco con learning rate = {} e initial cost = {} <--->\".format(learning_rate[j],initial_const[i]))\n",
    "                for filename in os.listdir(dataset_dir):\n",
    "                    if filename.endswith(\".jpg\") or filename.endswith(\".jpeg\"):\n",
    "                        person_path = os.path.join(dataset_dir, filename)\n",
    "                        test_img = load_image_NN1(person_path,device)\n",
    "                        test_img = test_img.numpy()\n",
    "                        \n",
    "                        test_images_adv = attack.generate(test_img)\n",
    "                        nn1_predictions = model_nn1.predict(test_images_adv)\n",
    "\n",
    "                        test_images_NN2 = load_test_image_NN2(test_images_adv)\n",
    "                        nn2_predictions = model_nn2.predict(test_images_NN2)\n",
    "\n",
    "                        correct_label = re.sub(r'_\\d+_face_0\\.jpg$', '', filename)\n",
    "                        #print(\"Etichetta corretta:\", correct_label)   \n",
    "                        perturbation.append(np.mean(np.abs((test_images_adv - test_img))))  #Salvo le perturbazioni applicate su ogni immagine\n",
    "                \n",
    "                        predicted_label_nn1 = LABELS[np.array(nn1_predictions.argmax())]\n",
    "                        predicted_label_nn2 = LABELS[np.array(nn2_predictions.argmax())]\n",
    "                        #print(\"Predetto {} con probabilità {} e con perturbazione {}\".format(predicted_label,model_predictions[0][model_predictions.argmax()],perturbation[-1]))\n",
    "                        total_images+=1\n",
    "                        \n",
    "                        predicted_label_nn1 = str(predicted_label_nn1)  # da togliere ?\n",
    "                        predicted_label_nn2 = str(predicted_label_nn2)\n",
    "                        \n",
    "                        if correct_label in predicted_label_nn1:\n",
    "                            correct_predictions_nn1+=1\n",
    "\n",
    "                        #print(\"Adversarial Sample misclassificati correttamente attuale: {}%\".format((100-(accuracy*100))))\n",
    "                        accuracy_nn1 = correct_predictions_nn1/total_images\n",
    "\n",
    "                        if correct_label in predicted_label_nn2:\n",
    "                            correct_predictions_nn2+=1\n",
    "\n",
    "                        accuracy_nn2 = correct_predictions_nn2/total_images\n",
    "\n",
    "\n",
    "                        if total_images == 500:\n",
    "                            print(\"Sei a 500 Immagini initial_cost:{} | learning_rate:{}\".format(initial_const[i], learning_rate[i]))\n",
    "\n",
    "                if total_images != 0:    \n",
    "                    if len(perturbation) == total_images:\n",
    "                        perturbazione_media = sum(perturbation)/total_images   # In media quanta pertubazione è stata applicata su ogni immagine \n",
    "                        perturbation_for_learning_rate_nn1[z][i][j] = perturbazione_media \n",
    "                        #print(\"----------- Perturbazione media aggiunta a tutte le immagini ---> {}% ----------------\".format(learning,perturbazione_media))\n",
    "                        \n",
    "                        \n",
    "                    final_accuracy_nn1 = correct_predictions_nn1/total_images          # Accuracy su tutte le immagini\n",
    "                    accuracy_for_learning_rate_nn1[z][i][j] = final_accuracy_nn1\n",
    "                    #print(\"----------- Accuracy sugli adversarial Sample equivale a ---> {}% ----------------\".format(learning,final_accuracy))\n",
    "                    final_accuracy_nn2 = correct_predictions_nn2/total_images\n",
    "                    accuracy_for_learning_rate_nn2[z][i][j] = final_accuracy_nn2\n",
    "                else:\n",
    "                    print(\"ERRORE TOTAL IMAGE == 0 ERRORE\")\n",
    "                        \n",
    "            learning_contatore = 0\n",
    "            print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------lllllllllllllllllll\")\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.  0.  0.2 0.2 0.4]]\n",
      "\n",
      " [[0.  0.  0.2 0.2 0.4]]]\n"
     ]
    }
   ],
   "source": [
    "#matrice righe = iterazione, colonne = learning rate\n",
    "print(accuracy_for_learning_rate_nn1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plot accuracy/Attack strength\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(learning_rate, perturbation_for_learning_rate[0], 'b-', label='Perturbazione')\n",
    "ax.plot(learning_rate, accuracy_for_learning_rate[0], 'r-', label='Accuracy')\n",
    "#ax.plot(np.array(learning_rate), np.array(perturbation_for_learning_rate[1]), 'r-', label='max_iter == 2')\n",
    "#ax.plot(np.array(learning_rate), np.array(perturbation_for_learning_rate[2]), 'g-.', label='max_iter == 4')\n",
    "\n",
    "legend = ax.legend(loc='upper center', shadow=True, fontsize='large')\n",
    "legend.get_frame().set_facecolor('#00FFCC')\n",
    "\n",
    "plt.ylabel('Perturbation')\n",
    "plt.xlabel('Learning Rate')\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grafico Accuracy media a ogni iterazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# plot accuracy/Attack strength\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(learning_rate, np.array(accuracy_for_learning_rate[0]), 'b--', label='initial cost == 1')\n",
    "ax.plot(learning_rate, np.array(accuracy_for_learning_rate[1]), 'r-', label='initial cost == 300')\n",
    "ax.plot(learning_rate, np.array(accuracy_for_learning_rate[2]), 'g-', label='initial cost == 700')\n",
    "\n",
    "legend = ax.legend(loc='upper center', shadow=True, fontsize='large')\n",
    "legend.get_frame().set_facecolor('#00FFCC')\n",
    "\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Learning Rate')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grafico Accuracy media/Perturbazione media\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(np.array(accuracy_for_max_iter), np.array(perturbation_for_max_iter), 'b--', label='NN1')\n",
    "\n",
    "legend = ax.legend(loc='upper center', shadow=True, fontsize='large')\n",
    "legend.get_frame().set_facecolor('#00FFCC')\n",
    "\n",
    "plt.xlabel('Attack strength (eps)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Attacco* **TARGETED**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETICHETTA TARGET:   Aaron_Hernandez\n",
      "Inizio Attacco CARLINI-WAGNER TARGETED\n",
      "<---> Attacco con max_iter = 2| learning rate = 0.3 | initial cost = 300 <--->\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C&W L_2: 100%|██████████| 1/1 [00:02<00:00,  2.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etichetta Corretta: Andrea_Pirlo | Predetto:  Andrea_Pirlo  probabilità 12.725250244140625 perturbazione applicata 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C&W L_2: 100%|██████████| 1/1 [00:02<00:00,  2.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etichetta Corretta: Antonio_Cassano | Predetto:  Branch_Warren  probabilità 10.506441116333008 perturbazione applicata 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C&W L_2: 100%|██████████| 1/1 [00:02<00:00,  2.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etichetta Corretta: Ariana_Grande | Predetto:  Ariana_Grande  probabilità 11.170966148376465 perturbazione applicata 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C&W L_2: 100%|██████████| 1/1 [00:02<00:00,  2.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etichetta Corretta: Ashley_Scott | Predetto:  Ashley_Scott  probabilità 13.896852493286133 perturbazione applicata 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C&W L_2: 100%|██████████| 1/1 [00:01<00:00,  1.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etichetta Corretta: Boris_Johnson | Predetto:  Boris_Johnson  probabilità 13.323941230773926 perturbazione applicata 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C&W L_2: 100%|██████████| 1/1 [00:02<00:00,  2.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etichetta Corretta: Brad_Pitt | Predetto:  Brad_Pitt  probabilità 13.206241607666016 perturbazione applicata 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C&W L_2: 100%|██████████| 1/1 [00:02<00:00,  2.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etichetta Corretta: Christian_De_Sica | Predetto:  Christian_De_Sica  probabilità 13.7531156539917 perturbazione applicata 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C&W L_2: 100%|██████████| 1/1 [00:02<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etichetta Corretta: Christopher_Nolan | Predetto:  Christopher_Nolan  probabilità 12.074438095092773 perturbazione applicata 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C&W L_2: 100%|██████████| 1/1 [00:02<00:00,  2.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etichetta Corretta: Cristiano_Ronaldo | Predetto:  Cristiano_Ronaldo  probabilità 12.945646286010742 perturbazione applicata 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C&W L_2: 100%|██████████| 1/1 [00:02<00:00,  2.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etichetta Corretta: Diego_Maradona | Predetto:  Diego_Maradona  probabilità 12.622477531433105 perturbazione applicata 0.0\n",
      "<---> Attacco con max_iter = 2| learning rate = 0.5 | initial cost = 300 <--->\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C&W L_2: 100%|██████████| 1/1 [00:02<00:00,  2.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etichetta Corretta: Andrea_Pirlo | Predetto:  Andrea_Pirlo  probabilità 12.725250244140625 perturbazione applicata 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C&W L_2: 100%|██████████| 1/1 [00:02<00:00,  2.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etichetta Corretta: Antonio_Cassano | Predetto:  Branch_Warren  probabilità 10.506441116333008 perturbazione applicata 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C&W L_2: 100%|██████████| 1/1 [00:02<00:00,  2.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etichetta Corretta: Ariana_Grande | Predetto:  Ariana_Grande  probabilità 11.170966148376465 perturbazione applicata 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C&W L_2: 100%|██████████| 1/1 [00:02<00:00,  2.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etichetta Corretta: Ashley_Scott | Predetto:  Ashley_Scott  probabilità 13.896852493286133 perturbazione applicata 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C&W L_2: 100%|██████████| 1/1 [00:02<00:00,  2.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etichetta Corretta: Boris_Johnson | Predetto:  Boris_Johnson  probabilità 13.323941230773926 perturbazione applicata 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C&W L_2: 100%|██████████| 1/1 [00:02<00:00,  2.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etichetta Corretta: Brad_Pitt | Predetto:  Brad_Pitt  probabilità 13.206241607666016 perturbazione applicata 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C&W L_2: 100%|██████████| 1/1 [00:02<00:00,  2.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etichetta Corretta: Christian_De_Sica | Predetto:  Christian_De_Sica  probabilità 13.7531156539917 perturbazione applicata 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C&W L_2: 100%|██████████| 1/1 [00:02<00:00,  2.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etichetta Corretta: Christopher_Nolan | Predetto:  Christopher_Nolan  probabilità 12.074438095092773 perturbazione applicata 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C&W L_2: 100%|██████████| 1/1 [00:02<00:00,  2.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etichetta Corretta: Cristiano_Ronaldo | Predetto:  Cristiano_Ronaldo  probabilità 12.945646286010742 perturbazione applicata 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C&W L_2: 100%|██████████| 1/1 [00:02<00:00,  2.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etichetta Corretta: Diego_Maradona | Predetto:  Diego_Maradona  probabilità 12.622477531433105 perturbazione applicata 0.0\n",
      "<---> Attacco con max_iter = 2| learning rate = 1 | initial cost = 300 <--->\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C&W L_2: 100%|██████████| 1/1 [00:02<00:00,  2.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etichetta Corretta: Andrea_Pirlo | Predetto:  Andrea_Pirlo  probabilità 12.725250244140625 perturbazione applicata 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C&W L_2: 100%|██████████| 1/1 [00:02<00:00,  2.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etichetta Corretta: Antonio_Cassano | Predetto:  Branch_Warren  probabilità 10.506441116333008 perturbazione applicata 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C&W L_2: 100%|██████████| 1/1 [00:02<00:00,  2.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etichetta Corretta: Ariana_Grande | Predetto:  Ariana_Grande  probabilità 11.170966148376465 perturbazione applicata 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C&W L_2: 100%|██████████| 1/1 [00:02<00:00,  2.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etichetta Corretta: Ashley_Scott | Predetto:  Ashley_Scott  probabilità 13.896852493286133 perturbazione applicata 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C&W L_2: 100%|██████████| 1/1 [00:02<00:00,  2.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etichetta Corretta: Boris_Johnson | Predetto:  Boris_Johnson  probabilità 13.323941230773926 perturbazione applicata 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C&W L_2: 100%|██████████| 1/1 [00:02<00:00,  2.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etichetta Corretta: Brad_Pitt | Predetto:  Brad_Pitt  probabilità 13.206241607666016 perturbazione applicata 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C&W L_2: 100%|██████████| 1/1 [00:02<00:00,  2.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etichetta Corretta: Christian_De_Sica | Predetto:  Christian_De_Sica  probabilità 13.7531156539917 perturbazione applicata 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C&W L_2: 100%|██████████| 1/1 [00:02<00:00,  2.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etichetta Corretta: Christopher_Nolan | Predetto:  Christopher_Nolan  probabilità 12.074438095092773 perturbazione applicata 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C&W L_2: 100%|██████████| 1/1 [00:02<00:00,  2.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etichetta Corretta: Cristiano_Ronaldo | Predetto:  Cristiano_Ronaldo  probabilità 12.945646286010742 perturbazione applicata 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C&W L_2: 100%|██████████| 1/1 [00:02<00:00,  2.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etichetta Corretta: Diego_Maradona | Predetto:  Diego_Maradona  probabilità 12.622477531433105 perturbazione applicata 0.0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 112\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;66;03m#print(\"----------- Accuracy sugli adversarial Sample equivale a ---> {}% ----------------\".format(learning,final_accuracy))\u001b[39;00m\n\u001b[0;32m    111\u001b[0m final_accuracy_nn2 \u001b[38;5;241m=\u001b[39m correct_predictions_nn2\u001b[38;5;241m/\u001b[39mtotal_images\n\u001b[1;32m--> 112\u001b[0m \u001b[43maccuracy_for_learning_rate_nn2\u001b[49m\u001b[43m[\u001b[49m\u001b[43mz\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m final_accuracy_nn2\n\u001b[0;32m    114\u001b[0m accuracy_misclassified_nn2 \u001b[38;5;241m=\u001b[39m correct_misclassified_nn2\u001b[38;5;241m/\u001b[39mtotal_images\n\u001b[0;32m    115\u001b[0m accuracy_misclassified_for_learning_rate_targeted_nn2[z][i][j] \u001b[38;5;241m=\u001b[39m accuracy_misclassified_nn2\n",
      "\u001b[1;31mTypeError\u001b[0m: 'numpy.float64' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "dataset_dir = \"test_set_cropped_piccolo/\" \n",
    "binary_search_steps = 3\n",
    "confidence = 0.7\n",
    "max_iter = [2]\n",
    "learning_rate = [0.3,0.5,1]\n",
    "initial_const = [300,700]\n",
    "\n",
    "correct_predictions_nn1 = 0\n",
    "correct_misclassified_nn1 = 0\n",
    "accuracy_for_learning_rate_targeted_nn1 = np.zeros((len(max_iter),len(initial_const),len(learning_rate)))        #riga-colonna\n",
    "perturbation_for_learning_rate_targeted_nn1 = np.zeros((len(max_iter),len(initial_const),len(learning_rate)))\n",
    "accuracy_misclassified_for_learning_rate_targeted_nn1 = np.zeros((len(max_iter),len(initial_const),len(learning_rate)))\n",
    "\n",
    "correct_predictions_nn2 = 0\n",
    "correct_misclassified_nn2 = 0\n",
    "accuracy_for_learning_rate_targeted_nn2 = np.zeros((len(max_iter),len(initial_const),len(learning_rate)))        #riga\n",
    "accuracy_misclassified_for_learning_rate_targeted_nn2 = np.zeros((len(max_iter),len(initial_const),len(learning_rate)))\n",
    "#perturbation_for_learning_rate_nn2 = np.zeros((len(initial_const),len(learning_rate)))\n",
    "\n",
    "target_class = 10\n",
    "etichetta_target = LABELS[target_class]\n",
    "print(\"ETICHETTA TARGET: \", etichetta_target)\n",
    "\n",
    "targeted_labels = target_class*np.ones(LABELS.size)\n",
    "one_hot_targeted_labels = tf.keras.utils.to_categorical(targeted_labels, num_classes = 8631)\n",
    "\n",
    "\n",
    "print(\"Inizio Attacco CARLINI-WAGNER TARGETED\")\n",
    "for z in range(len(max_iter)):\n",
    "    for i in range(len(initial_const)):\n",
    "            for j in range(len(learning_rate)):   #Se qualcosa funziona strano controllare questo zip\n",
    "                correct_predictions_nn1 = 0\n",
    "                correct_predictions_nn2 = 0\n",
    "                correct_misclassified_nn1 = 0\n",
    "                correct_misclassified_nn2 = 0\n",
    "                total_images = 0\n",
    "                perturbation = []\n",
    "                \n",
    "                attack = CarliniL2Method(classifier=model_nn1,\n",
    "                                          binary_search_steps=binary_search_steps,\n",
    "                                            confidence=confidence, max_iter=max_iter[z],\n",
    "                                              learning_rate=learning_rate[j],\n",
    "                                                initial_const=initial_const[i],\n",
    "                                                  targeted=True)\n",
    "                \n",
    "                print(\"<---> Attacco con max_iter = {}| learning rate = {} | initial cost = {} <--->\".format(max_iter[z],learning_rate[j],initial_const[i]))\n",
    "                for filename in os.listdir(dataset_dir):\n",
    "                    person_path = os.path.join(dataset_dir, filename)\n",
    "                    test_img = load_image_NN1(person_path,device)\n",
    "                    test_img = test_img.numpy()\n",
    "                    test_images_adv = attack.generate(test_img,one_hot_targeted_labels)\n",
    "                    nn1_predictions = model_nn1.predict(test_images_adv)\n",
    "                    perturbation.append(np.mean(np.abs((test_images_adv - test_img))))\n",
    "                    \n",
    "                    test_images_NN2 = load_test_image_NN2(test_images_adv)\n",
    "                    nn2_predictions = model_nn2.predict(test_images_NN2)\n",
    "\n",
    "                    correct_label = re.sub(r'_\\d+_face_0\\.jpg$', '', filename)  \n",
    "                      #Salvo le perturbazioni applicate su ogni immagine\n",
    "            \n",
    "                    predicted_label_nn1 = LABELS[np.array(nn1_predictions.argmax())]\n",
    "                    predicted_label_nn2 = LABELS[np.array(nn2_predictions.argmax())]\n",
    "                    print(\"Etichetta Corretta: {} | Predetto: {}  probabilità {} perturbazione applicata {}\".format(correct_label,predicted_label_nn1,nn1_predictions[0][nn1_predictions.argmax()],perturbation[-1]))\n",
    "                    total_images+=1\n",
    "                    \n",
    "                    predicted_label_nn1 = str(predicted_label_nn1)  # da togliere ?\n",
    "                    predicted_label_nn2 = str(predicted_label_nn2)\n",
    "                    \n",
    "                    if correct_label in predicted_label_nn1:\n",
    "                        correct_predictions_nn1+=1\n",
    "\n",
    "                    #print(\"Adversarial Sample misclassificati correttamente attuale: {}%\".format((100-(accuracy*100))))\n",
    "                    accuracy_nn1 = correct_predictions_nn1/total_images\n",
    "                    \n",
    "                    if correct_label in predicted_label_nn2:\n",
    "                        correct_predictions_nn2+=1\n",
    "\n",
    "                    accuracy_nn2 = correct_predictions_nn2/total_images\n",
    "                            \n",
    "                    if etichetta_target in predicted_label_nn1:  \n",
    "                        correct_misclassified_nn1 += 1   #Se il modello predice l'etichetta target allora è correttamente misclassificato\n",
    "\n",
    "                    accuracy_misclassified_nn1 = correct_misclassified_nn1/total_images\n",
    "\n",
    "                    if etichetta_target in predicted_label_nn2:   #se Attacco su NN2 Correttamente riuscito\n",
    "                        correct_misclassified_nn2 += 1   \n",
    "\n",
    "                    accuracy_misclassified_nn2 = correct_misclassified_nn2/total_images\n",
    "                    \n",
    "                    #print(\"Adversarial Sample misclassificati correttamente attualmente: {}%\".format((accuracy_misclassified)))\n",
    "                    #print(\"Accuracy attuale: {}%\".format((correct_predictions/total_images)*100))\n",
    "                \n",
    "                    if total_images == 500:\n",
    "                        print(\"Sei a 500 Immagini initial_cost:{} | learning_rate:{}\".format(initial_const[i], learning_rate[i]))\n",
    "\n",
    "            if total_images != 0:    \n",
    "                if len(perturbation) == total_images:\n",
    "                      # In media quanta pertubazione è stata applicata su ogni immagine\n",
    "                    perturbation_for_learning_rate_targeted_nn1[z][i][j] = (sum(perturbation)/total_images)\n",
    "                    \n",
    "                \n",
    "   \n",
    "                      \n",
    "                final_accuracy_nn1 = correct_predictions_nn1/total_images          # Accuracy su tutte le immagini\n",
    "                accuracy_for_learning_rate_targeted_nn2[z][i][j] = final_accuracy_nn1\n",
    "\n",
    "                accuracy_misclassified_nn1 = correct_misclassified_nn1/total_images\n",
    "                accuracy_misclassified_for_learning_rate_targeted_nn1[z][i][j] = accuracy_misclassified_nn1\n",
    "\n",
    "                #print(\"----------- Accuracy sugli adversarial Sample equivale a ---> {}% ----------------\".format(learning,final_accuracy))\n",
    "                final_accuracy_nn2 = correct_predictions_nn2/total_images\n",
    "                accuracy_for_learning_rate_nn2[z][i][j] = final_accuracy_nn2\n",
    "\n",
    "                accuracy_misclassified_nn2 = correct_misclassified_nn2/total_images\n",
    "                accuracy_misclassified_for_learning_rate_targeted_nn2[z][i][j] = accuracy_misclassified_nn2\n",
    "            else:\n",
    "                print(\"ERRORE TOTAL IMAGE == 0 ERRORE\")\n",
    "        \n",
    "    print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\")\n",
    "    print(\"\")\n",
    "    \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Matrice Accuracy' + str(learning_rate))\n",
    "for row_name, row_data in zip(initial_const, accuracy_for_learning_rate_targeted_nn1[0]):\n",
    "    print(f'        {row_name }   ' + '  '.join(map(str, row_data)))\n",
    "\n",
    "\n",
    "print('Matrice Perturbation' + str(learning_rate))\n",
    "for row_name, row_data in zip(initial_const, perturbation_for_learning_rate_targeted):\n",
    "    print(f'        {row_name}         ' + '  '.join(map(str, row_data)))\n",
    "\n",
    "\n",
    "print('Matrice Misclassificazione' + str(learning_rate))\n",
    "for row_name, row_data in zip(initial_const, accuracy_misclassified_for_learning_rate):\n",
    "    print(f'        {row_name}         ' + '  '.join(map(str, row_data)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "[[0.  0.  0.9]\n",
      " [0.  0.  0.9]]\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_for_learning_rate_targeted_nn1[0])\n",
    "\n",
    "print(accuracy_for_learning_rate_targeted_nn2[0])\n",
    "\n",
    "print(accuracy_misclassified_for_learning_rate_targeted_nn2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot accuracy/Attack strength\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(learning_rate, perturbation_for_learning_rate_targeted[0], 'b-', label='Perturbazione')\n",
    "ax.plot(learning_rate, accuracy_for_learning_rate_targeted[0], 'r-', label='Accuracy')\n",
    "#ax.plot(np.array(learning_rate), np.array(perturbation_for_learning_rate[1]), 'r-', label='max_iter == 2')\n",
    "#ax.plot(np.array(learning_rate), np.array(perturbation_for_learning_rate[2]), 'g-.', label='max_iter == 4')\n",
    "\n",
    "legend = ax.legend(loc='upper center', shadow=True, fontsize='large')\n",
    "legend.get_frame().set_facecolor('#00FFCC')\n",
    "\n",
    "plt.ylabel('Perturbation')\n",
    "plt.xlabel('Learning Rate')\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Caricamento di una sola immagine per i test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"test_set_cropped/Brad_Pitt_1_face_0.jpg\"\n",
    "test_img = load_image(filename)\n",
    "\n",
    "print(test_img.shape)\n",
    "print(test_img.size)\n",
    "test_img = test_img.unsqueeze(0)\n",
    "print(test_img.shape)\n",
    "print(test_img.size)\n",
    "test_img = test_img.numpy()\n",
    "print(test_img.shape)\n",
    "print(type(test_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_search_steps = 5\n",
    "confidence = 0.7\n",
    "max_iter = 7\n",
    "learning_rate = 0.001\n",
    "initial_const = 350\n",
    "\n",
    "target_class = 100\n",
    "etichetta_target = LABELS[target_class]\n",
    "print(\"ETICHETTA TARGET: \", etichetta_target)\n",
    "\n",
    "targeted_labels = target_class*np.ones(LABELS.size)\n",
    "one_hot_targeted_labels = tf.keras.utils.to_categorical(targeted_labels, num_classes = 8631)\n",
    "\n",
    "attack = CarliniL2Method(classifier=classifier, binary_search_steps=binary_search_steps, confidence=confidence, max_iter=max_iter, learning_rate=learning_rate, initial_const=initial_const, targeted=True)\n",
    "test_images_adv = attack.generate(test_img, one_hot_targeted_labels)\n",
    "model_predictions = classifier.predict(test_images_adv)\n",
    "correct_label = re.sub(r'_\\d+_face_0\\.jpg$', '', filename)   \n",
    "perturbation.append(np.mean(np.abs((test_images_adv - test_img))))  \n",
    "predicted_label = LABELS[np.array(model_predictions[0].argmax())]\n",
    "print(\"Etichetta reale:{} || Predetto: {} con probabilità: {} e con perturbazione: {}\".format(correct_label,predicted_label,model_predictions[0][model_predictions.argmax()],perturbation[-1]))\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepara le immagini per la visualizzazione\n",
    "# Rimuovi la dimensione batch extra e converti nel formato channels-last\n",
    "\n",
    "test_images_adv = np.squeeze(test_images_adv, axis=0)\n",
    "test_images_adv = np.transpose(test_images_adv, (1, 2, 0))\n",
    "\n",
    "# Converti le immagini in uint8 per la visualizzazione\n",
    "if test_img.dtype != np.uint8:\n",
    "    test_img_numpy = (test_img * 255).astype(np.uint8)\n",
    "    test_img_numpy = np.squeeze(test_img_numpy, axis=0)  # Rimuovi la dimensione batch extra\n",
    "    test_img_numpy = np.transpose(test_img_numpy, (1, 2, 0))\n",
    "\n",
    "if test_images_adv.dtype != np.uint8:\n",
    "    test_images_adv = (test_images_adv * 255).astype(np.uint8)\n",
    "\n",
    "# Visualizza le immagini affiancate con Matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "# Mostra l'immagine originale\n",
    "ax1.imshow(test_img_numpy)\n",
    "ax1.set_title('Original Image')\n",
    "ax1.axis('off')\n",
    "\n",
    "# Mostra l'immagine avversaria\n",
    "ax2.imshow(test_images_adv)\n",
    "ax2.set_title(f'Adversarial Image\\nPredicted: {predicted_label}')\n",
    "ax2.axis('off')\n",
    "\n",
    "# Mostra la figura\n",
    "plt.suptitle(\"DeepFool Adversarial Images\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "artoolbox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
