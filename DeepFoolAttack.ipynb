{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install facenet-pytorch\n",
    "!pip install Pillow\n",
    "!pip install -q tensorflow==2.0.0\n",
    "!pip install adversarial-robustness-toolbox[all]\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# initialization\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIBRERIE UTILI\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import art\n",
    "\n",
    "if tf.__version__[0] != '2':\n",
    "    raise ImportError('This notebook requires TensorFlow v2.')\n",
    "\n",
    "print(\"GPU Available: \", tf.test.is_gpu_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from facenet_pytorch import InceptionResnetV1\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "resnet = InceptionResnetV1(pretrained='vggface2').eval()\n",
    "resnet.classify = True\n",
    "\n",
    "\n",
    "\n",
    "fpath = tf.keras.utils.get_file('rcmalli_vggface_labels_v2.npy',\n",
    "                             \"https://github.com/rcmalli/keras-vggface/releases/download/v2.0/rcmalli_vggface_labels_v2.npy\",\n",
    "                             cache_subdir=\"./\")\n",
    "LABELS = np.load(fpath)\n",
    "\n",
    "def load_image(filename):\n",
    "    img = Image.open(filename)\n",
    "    rsz = img.resize((160, 160))\n",
    "    tns = transforms.ToTensor()(rsz)\n",
    "    return tns\n",
    "\n",
    "model = PyTorchClassifier(resnet,input_shape=[224,224], loss=CrossEntropyLoss(),nb_classes=8631) #This class implements a classifier with the PyTorch framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "def load_image(filename):\n",
    "    img = Image.open(filename)\n",
    "    rsz = img.resize((160, 160))\n",
    "    tns = transforms.ToTensor()(rsz)\n",
    "    tns = tns.unsqueeze(0)\n",
    "    img_np  = tns.numpy()\n",
    "    return img_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import attack\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "\n",
    "#Impostare l'input shape\n",
    "classifier = PyTorchClassifier(resnet,input_shape=[224,224], loss=CrossEntropyLoss(),nb_classes=8631) #This class implements a classifier with the PyTorch framework.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Untargeted Attack on all test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from art.attacks.evasion import DeepFool\n",
    "import os\n",
    "import re\n",
    "\n",
    "dataset_dir = \"test_set_cropped_piccolo/\" \n",
    "eps_range = [1e-09, 1e-07,  1e-05, 1e-03, 1e-02, 1e00] #La dimensione del passo della variazione dell'input a ogni iterazione. Questo parametro definisce quanto grande sarà ogni passo nella direzione del gradiente. #La dimensione del passo della variazione dell'input per il calcolo della perturbazione minima. Questo parametro è utilizzato quando minimal è impostato su True.\n",
    "\n",
    "max_iter = 5  # Il numero massimo di iterazioni. Questo parametro determina quante volte l'attacco iterativo sarà eseguito.\n",
    " \n",
    "accuracy_for_eps = []\n",
    "perturbation_for_eps = []\n",
    "correct_predictions = 0\n",
    "total_images = 0\n",
    "print(\"Inizio Attacco DeepFool NON-TARGETED\")\n",
    "\n",
    "    \n",
    "for eps in eps_range:   \n",
    "    correct_predictions = 0\n",
    "    total_images = 0\n",
    "    perturbation = []        \n",
    "    attack = DeepFool(classifier=classifier, epsilon=eps, max_iter=max_iter)\n",
    "            \n",
    "    print(\"**** Attacco con eps:{} ****\".format(eps))\n",
    "    for filename in os.listdir(dataset_dir):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".jpeg\"):\n",
    "            person_path = os.path.join(dataset_dir, filename)\n",
    "            test_img = load_image(person_path)\n",
    "            test_images_adv = attack.generate(test_img)\n",
    "            model_predictions = model.predict(test_images_adv)\n",
    "            correct_label = re.sub(r'_\\d+_face_0\\.jpg$', '', filename)\n",
    "            #print(\"Etichetta corretta:\", correct_label)   \n",
    "            perturbation.append(np.mean(np.abs((test_images_adv - test_img))))  #Salvo le perturbazioni applicate su ogni immagine\n",
    "            predicted_label = LABELS[np.array(model_predictions[0].argmax())]\n",
    "            #print(\"Predetto {} con probabilità {} e con perturbazione {}\".format(predicted_label,model_predictions[0][model_predictions.argmax()],perturbation[-1]))\n",
    "            total_images+=1\n",
    "            predicted_label = str(predicted_label)\n",
    "\n",
    "            if correct_label in predicted_label:\n",
    "                correct_predictions+=1\n",
    "\n",
    "                #accuracy = correct_predictions/total_images\n",
    "                #print(\"Adversarial Sample misclassificati correttamente attuale: {}%\".format((100-(accuracy*100))))\n",
    "            \n",
    "\n",
    "    if total_images != 0:    #Per ogni epsilon impostata salvo in accuracy plot\n",
    "        if len(perturbation) == total_images:\n",
    "            perturbazione_media = sum(perturbation)/total_images    #Calcolo la media delle perturbazioni applicate su tutte le immagini per una determinata epsilon\n",
    "            perturbation_for_eps.append(perturbazione_media)\n",
    "            #print(\"----------- Perturbazione media aggiunta a tutte le immagini per eps_Step: {} equivale a {}% ----------------\".format(eps,perturbazione_media))\n",
    "\n",
    "            final_accuracy = correct_predictions/total_images\n",
    "            accuracy_for_eps.append(final_accuracy)\n",
    "            #print(\"----------- Accuracy sugli adversarial Sample per eps_step: {} equivale a {}% ----------------\".format(eps,final_accuracy))\n",
    "        #print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_for_eps)\n",
    "print(perturbation_for_eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# plot accuracy/Attack strength\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(np.array(eps_range), np.array(accuracy_for_eps), 'b--', label='NN1')\n",
    "\n",
    "legend = ax.legend(loc='upper center', shadow=True, fontsize='large')\n",
    "legend.get_frame().set_facecolor('#00FFCC')\n",
    "\n",
    "plt.xlabel('Attack strength (eps)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(np.array(eps_range), np.array(perturbation_for_eps), 'b--', label='NN1')\n",
    "\n",
    "legend = ax.legend(loc='upper center', shadow=True, fontsize='large')\n",
    "legend.get_frame().set_facecolor('#00FFCC')\n",
    "\n",
    "plt.xlabel('Attack strength (eps)')\n",
    "plt.ylabel('mean perturbation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single sample Untargeted attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from art.attacks.evasion import DeepFool\n",
    "\n",
    "epsilon = 0.1\n",
    "max_iter = 10\n",
    "\n",
    "attack = DeepFool(classifier=classifier, epsilon=epsilon, max_iter=max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = load_image(\"test_set_cropped/Brad_Pitt_8_face_0.jpg\")\n",
    "\n",
    "test_img = test_img.unsqueeze(0)\n",
    "test_img_numpy  = test_img.numpy()\n",
    "test_images_adv = attack.generate(test_img_numpy)\n",
    "model_predictions = model.predict(test_images_adv)\n",
    "predicted_label = LABELS[np.array(model_predictions[0].argmax())]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepara le immagini per la visualizzazione\n",
    "# Rimuovi la dimensione batch extra e converti nel formato channels-last\n",
    "test_images_adv = np.squeeze(test_images_adv, axis=0)\n",
    "test_images_adv = np.transpose(test_images_adv, (1, 2, 0))\n",
    "\n",
    "# Converti le immagini in uint8 per la visualizzazione\n",
    "if test_img_numpy.dtype != np.uint8:\n",
    "    test_img_numpy = (test_img_numpy * 255).astype(np.uint8)\n",
    "    test_img_numpy = np.squeeze(test_img_numpy, axis=0)  # Rimuovi la dimensione batch extra\n",
    "    test_img_numpy = np.transpose(test_img_numpy, (1, 2, 0))\n",
    "\n",
    "if test_images_adv.dtype != np.uint8:\n",
    "    test_images_adv = (test_images_adv * 255).astype(np.uint8)\n",
    "\n",
    "# Visualizza le immagini affiancate con Matplotlib\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "# Mostra l'immagine originale\n",
    "ax1.imshow(test_img_numpy)\n",
    "ax1.set_title('Original Image')\n",
    "ax1.axis('off')\n",
    "\n",
    "# Mostra l'immagine avversaria\n",
    "ax2.imshow(test_images_adv)\n",
    "ax2.set_title(f'Adversarial Image\\nPredicted: {predicted_label}')\n",
    "ax2.axis('off')\n",
    "\n",
    "# Mostra la figura\n",
    "plt.suptitle(\"DeepFool Adversarial Images\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
