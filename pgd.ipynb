{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDG ATTACK "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Import*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from art.attacks.evasion import ProjectedGradientDescentPyTorch\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### initialization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if str(device) in 'cuda':\n",
    "    print(\"Import Inception.Inception\")\n",
    "    import inception\n",
    "    resnet = inception.InceptionResnetV1(pretrained='vggface2').eval()\n",
    "elif str(device) == \"cpu\":\n",
    "    print(\"Import Facenet.Inception\")\n",
    "    from facenet_pytorch import InceptionResnetV1\n",
    "    resnet = InceptionResnetV1(pretrained='vggface2').eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_labels\n",
    "\n",
    "\n",
    "resnet.classify = True\n",
    "resnet.to(device)\n",
    "LABELS = get_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "from art.attacks.evasion import ProjectedGradientDescentPyTorch\n",
    "\n",
    "\n",
    "#Impostare l'input shape\n",
    "model_resnet = PyTorchClassifier(resnet,input_shape=[224,224], loss=CrossEntropyLoss(),nb_classes=8631, device_type=device) #This class implements a classifier with the PyTorch framework.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SENet import SENet\n",
    "from utils import get_labels\n",
    "from utils import load_state_dict\n",
    "\n",
    "senet = SENet.senet50(num_classes=8631, include_top=True)\n",
    "\n",
    "load_state_dict(senet,'senet50_scratch_weight.pkl')\n",
    "senet.eval()\n",
    "\n",
    "model_senet = PyTorchClassifier(senet,input_shape=[224,224], loss=CrossEntropyLoss(),nb_classes=8631, device_type=device)\n",
    "\n",
    "LABELS = get_labels()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Untargeted Attack on all test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PGD generic Attack for all samples\n",
    "import os\n",
    "import re\n",
    "from utils import load_image_NN1, load_test_image_NN2\n",
    "\n",
    "dataset_dir = \"test_set_cropped_piccolo/\" \n",
    "eps_step = [0.000001, 0.00001, 0.0001, 0.0003, 0.0005, 0.0007, 0.001, 0.005, 0.007, 0.01] #La dimensione del passo della variazione dell'input a ogni iterazione. Questo parametro definisce quanto grande sarà ogni passo nella direzione del gradiente. #La dimensione del passo della variazione dell'input per il calcolo della perturbazione minima. Questo parametro è utilizzato quando minimal è impostato su True.\n",
    "max_iter = [2,5,7]  # Il numero massimo di iterazioni. Questo parametro determina quante volte l'attacco iterativo sarà eseguito.\n",
    " \n",
    "eps_range = 0.01 #Questo valore determina l'ampiezza massima della perturbazione aggiunta agli input originali. Può essere un valore singolo (int o float) o un array numpy (ndarray).\n",
    "\n",
    "accuracy_for_eps_resnet = np.zeros((len(max_iter),len(eps_step)))\n",
    "perturbation_for_eps_resnet = np.zeros((len(max_iter),len(eps_step)))\n",
    "correct_predictions_resnet = 0\n",
    "\n",
    "accuracy_for_eps_senet = np.zeros((len(max_iter),len(eps_step)))\n",
    "perturbation_for_eps_senet = np.zeros((len(max_iter),len(eps_step)))\n",
    "correct_predictions_senet = 0\n",
    "\n",
    "total_images = 0\n",
    "print(\"Inizio Attacco PGD NON-TARGETED\")\n",
    "for i in range(len(max_iter)):\n",
    "        print(\"**** Attacco con max_iter {} **** \".format(max_iter[i]))\n",
    "        for j in range(len(eps_step)):   #Se qualcosa funziona strano controllare questo zip\n",
    "            correct_predictions_resnet = 0\n",
    "            correct_predictions_senet = 0\n",
    "            total_images = 0\n",
    "            perturbation = []\n",
    "            \n",
    "            attack = ProjectedGradientDescentPyTorch(estimator=model_resnet, eps = eps_range, eps_step=eps_step[j], targeted=False, max_iter = max_iter[i])\n",
    "            \n",
    "            print(\"**** Attacco con eps:{} con step a {} ****\".format(eps_range,eps_step[j]))\n",
    "            for filename in os.listdir(dataset_dir):\n",
    "                if filename.endswith(\".jpg\") or filename.endswith(\".jpeg\"):\n",
    "                    person_path = os.path.join(dataset_dir, filename)\n",
    "                    test_img = load_image_NN1(person_path)\n",
    "                    test_img = test_img.numpy()\n",
    "                    test_images_adv = attack.generate(test_img)\n",
    "                    resnet_predictions = model_resnet.predict(test_images_adv)\n",
    "\n",
    "                    test_images_NN2 = load_test_image_NN2(test_images_adv)\n",
    "\n",
    "\n",
    "                    senet_predictions = model_senet.predict(test_images_NN2)\n",
    "\n",
    "                    correct_label = re.sub(r'_\\d+_face_0\\.jpg$', '', filename)\n",
    "                    #print(\"Etichetta corretta:\", correct_label)   \n",
    "                    perturbation.append(np.mean(np.abs((test_images_adv - test_img))))  #Salvo le perturbazioni applicate su ogni immagine\n",
    "            \n",
    "                    predicted_label_resnet = LABELS[np.array(resnet_predictions.argmax())]\n",
    "                    predicted_label_senet = LABELS[np.array(senet_predictions.argmax())]\n",
    "                    #print(\"Predetto {} con probabilità {} e con perturbazione {}\".format(predicted_label,model_predictions[0][model_predictions.argmax()],perturbation[-1]))\n",
    "                    total_images+=1\n",
    "                    \n",
    "                    predicted_label_resnet = str(predicted_label_resnet)  # da togliere ?\n",
    "\n",
    "                    \n",
    "                    if correct_label in predicted_label_resnet:\n",
    "                        correct_predictions_resnet+=1\n",
    "\n",
    "                    #print(\"Adversarial Sample misclassificati correttamente attuale: {}%\".format((100-(accuracy*100))))\n",
    "                    accuracy_resnet = correct_predictions_resnet/total_images\n",
    "\n",
    "                    if correct_label in predicted_label_senet:\n",
    "                        correct_predictions_senet+=1\n",
    "\n",
    "                    accuracy_senet = correct_predictions_senet/total_images    \n",
    "\n",
    "                    \n",
    "            \n",
    "\n",
    "            if total_images != 0:    #Per ogni epsilon impostata salvo in accuracy plot\n",
    "                if len(perturbation) == total_images:\n",
    "                    perturbazione_media = sum(perturbation)/total_images    #Calcolo la media delle perturbazioni applicate su tutte le immagini per una determinata epsilon\n",
    "                    perturbation_for_eps_resnet[i][j] = perturbazione_media\n",
    "                    #print(\"----------- Perturbazione media aggiunta a tutte le immagini per eps_Step: {} equivale a {}% ----------------\".format(eps_step[j],perturbazione_media))\n",
    "\n",
    "\n",
    "                final_accuracy_resenet = correct_predictions_resnet/total_images\n",
    "                accuracy_for_eps_resnet[i][j] = final_accuracy_resenet\n",
    "\n",
    "                final_accuracy_senet = correct_predictions_senet/total_images\n",
    "                accuracy_for_eps_senet[i][j] = final_accuracy_senet\n",
    "                #print(\"----------- Accuracy sugli adversarial Sample per eps_step: {} equivale a {}% ----------------\".format(eps_step[j],final_accuracy))\n",
    "                #print(\"\")\n",
    "            #Per ogni epsilon impostata salvo in accuracy plot\n",
    "       #print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\")\n",
    "       #print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# plot accuracy/Attack strength\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(np.array(eps_step), np.array(accuracy_for_eps_resnet[0]), 'b--', label='NN1')\n",
    "ax.plot(np.array(eps_step), np.array(accuracy_for_eps_senet[0]), 'r--', label='NN2')\n",
    "\n",
    "legend = ax.legend(loc='upper center', shadow=True, fontsize='large')\n",
    "legend.get_frame().set_facecolor('#00FFCC')\n",
    "\n",
    "plt.xlabel('Attack strength (eps)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_for_eps_resnet[0])\n",
    "print(accuracy_for_eps_senet[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(np.array(perturbation_for_eps_resnet), np.array(accuracy_for_eps_resnet[0]), 'b--', label='NN1')\n",
    "\n",
    "legend = ax.legend(loc='upper center', shadow=True, fontsize='large')\n",
    "legend.get_frame().set_facecolor('#00FFCC')\n",
    "\n",
    "plt.xlabel('Attack strength (eps)')\n",
    "plt.ylabel('mean perturbation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single sample Untargeted attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 0.01\n",
    "eps_step = 0.0000005\n",
    "max_iter = 3 \n",
    "\n",
    "attack = ProjectedGradientDescentPyTorch(estimator=model_resnet, eps = epsilon, eps_step= eps_step, targeted=False, max_iter = max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_image_NN1, load_test_image_NN2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "dataset_dir = \"test_set_cropped_piccolo/\"\n",
    "filename = \"Brad_Pitt_1_face_0.jpg\"\n",
    "person_path = os.path.join(dataset_dir, filename)\n",
    "\n",
    "test_img = load_image_NN1(person_path)\n",
    "test_img_numpy = test_img.numpy()\n",
    "test_images_adv = attack.generate(test_img_numpy)\n",
    "\n",
    "\n",
    "resnet_predictions = model_resnet.predict(test_images_adv)\n",
    "perturbation = np.mean(np.abs((test_images_adv - test_img_numpy)))\n",
    "print('Average perturbation: {:4.2f}'.format(perturbation))\n",
    "\n",
    "\n",
    "test_images_NN2 = load_test_image_NN2(test_images_adv)\n",
    "\n",
    "\n",
    "senet_predictions = model_senet.predict(test_images_NN2)\n",
    "\n",
    "\n",
    "predicted_label_resnet = LABELS[np.array(resnet_predictions.argmax())]\n",
    "predicted_label_senet = LABELS[np.array(senet_predictions.argmax())]\n",
    "print(\"NN1{} con probabilità {}\".format(predicted_label_resnet,resnet_predictions[0][resnet_predictions.argmax()]))\n",
    "print(\"NN2{} con probabilità {}\".format(predicted_label_senet,senet_predictions[0][senet_predictions.argmax()]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepara le immagini per la visualizzazione\n",
    "# Rimuovi la dimensione batch extra e converti nel formato channels-last\n",
    "test_images_adv = np.squeeze(test_images_adv, axis=0)\n",
    "test_images_adv = np.transpose(test_images_adv, (1, 2, 0))\n",
    "\n",
    "# Converti le immagini in uint8 per la visualizzazione\n",
    "if test_img_numpy.dtype != np.uint8:\n",
    "    test_img_numpy = (test_img_numpy * 255).astype(np.uint8)\n",
    "    test_img_numpy = np.squeeze(test_img_numpy, axis=0)  # Rimuovi la dimensione batch extra\n",
    "    test_img_numpy = np.transpose(test_img_numpy, (1, 2, 0))\n",
    "\n",
    "if test_images_adv.dtype != np.uint8:\n",
    "    test_images_adv = (test_images_adv * 255).astype(np.uint8)\n",
    "\n",
    "# Visualizza le immagini affiancate con Matplotlib\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "# Mostra l'immagine originale\n",
    "ax1.imshow(test_img_numpy)\n",
    "ax1.set_title('Original Image')\n",
    "ax1.axis('off')\n",
    "\n",
    "# Mostra l'immagine avversaria\n",
    "ax2.imshow(test_images_adv)\n",
    "ax2.set_title(f'Adversarial Image\\nPredicted: {predicted_label}')\n",
    "ax2.axis('off')\n",
    "\n",
    "# Mostra la figura\n",
    "plt.suptitle(\"DeepFool Adversarial Images\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Targeted Attack on all test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PGD specific Attack for all samples\n",
    "import os\n",
    "import re\n",
    "import torch\n",
    "from utils import load_image_NN1\n",
    "\n",
    "dataset_dir = \"test_set_cropped_piccolo/\" \n",
    "eps_step = [2e-05, 5e-05, 7e-05, 2e-03, 5e-03, 7e-03, 2e-02, 5e-02, 7e-02, 1e-01] #La dimensione del passo della variazione dell'input a ogni iterazione. Questo parametro definisce quanto grande sarà ogni passo nella direzione del gradiente. #La dimensione del passo della variazione dell'input per il calcolo della perturbazione minima. Questo parametro è utilizzato quando minimal è impostato su True.\n",
    "\n",
    "max_iter = [2,5,7]  # Il numero massimo di iterazioni. Questo parametro determina quante volte l'attacco iterativo sarà eseguito.\n",
    "\n",
    "eps_range = 0.1  # Questo valore determina l'ampiezza massima della perturbazione aggiunta agli input originali. Può essere un valore singolo (int o float) o un array numpy (ndarray).\n",
    "\n",
    "accuracy_misclassified_for_eps = np.zeros((len(max_iter),len(eps_step)))\n",
    "\n",
    "accuracy_for_eps = np.zeros((len(max_iter),len(eps_step)))\n",
    "\n",
    "perturbation_for_eps = np.zeros((len(max_iter),len(eps_step)))\n",
    "\n",
    "correct_misclassified = 0\n",
    "total_images = 0\n",
    "\n",
    "target_class = 10\n",
    "etichetta_target = LABELS[0]\n",
    "print(\"ETICHETTA TARGET: \", LABELS[10])\n",
    "shape = 1 #shape di test image \n",
    "batch_size = shape\n",
    "targeted_labels = np.array([target_class] * batch_size)\n",
    "one_hot_targeted_labels = tf.keras.utils.to_categorical(targeted_labels, num_classes=8631)\n",
    "\n",
    "print(\"Inizio Attacco PGD NON-TARGETED\")\n",
    "for i in range(len(max_iter)):\n",
    "        print(\"**** Attacco con max_iter {} **** \".format(max_iter[i]))\n",
    "        for j in range(len(eps_step)):   #Se qualcosa funziona strano controllare questo zip\n",
    "            correct_predictions = 0\n",
    "            total_images = 0\n",
    "            perturbation = []\n",
    "            \n",
    "            attack = ProjectedGradientDescentPyTorch(estimator=model, eps = eps_range, eps_step=eps_step[j], targeted=True, max_iter = max_iter[i])\n",
    "            \n",
    "            print(\"**** Attacco con eps:{} con step a {} ****\".format(eps_range,eps_step[j]))\n",
    "            for filename in os.listdir(dataset_dir):\n",
    "                if filename.endswith(\".jpg\") or filename.endswith(\".jpeg\"):\n",
    "                    person_path = os.path.join(dataset_dir, filename)\n",
    "                    test_img = load_image_NN1(person_path)\n",
    "                    test_img = test_img.numpy()\n",
    "                    test_images_adv = attack.generate(test_img, one_hot_targeted_labels)\n",
    "                    model_predictions = model.predict(test_images_adv)\n",
    "                    correct_label = re.sub(r'_\\d+_face_0\\.jpg$', '', filename)\n",
    "                    print(\"Etichetta corretta:\", correct_label)   \n",
    "                    perturbation.append(np.mean(np.abs((test_images_adv - test_img))))  #Salvo le perturbazioni applicate su ogni immagine\n",
    "                    predicted_label = LABELS[np.array(model_predictions[0].argmax())]\n",
    "                    print(\"Predetto {} con probabilità {} e con perturbazione {}\".format(predicted_label,model_predictions[0][model_predictions.argmax()],perturbation[-1]))\n",
    "                    total_images+=1\n",
    "                    \n",
    "                    predicted_label = str(predicted_label)\n",
    "\n",
    "                    if correct_label in predicted_label:\n",
    "                        correct_predictions+=1\n",
    "                        \n",
    "                    if etichetta_target in predicted_label:  \n",
    "                        correct_misclassified = correct_misclassified+1   #Se il modello predice l'etichetta target allora è correttamente misclassificato\n",
    "\n",
    "                    accuracy_misclassified = correct_misclassified/total_images\n",
    "                    print(\"Adversarial Sample misclassificati correttamente attualmente: {}%\".format((accuracy_misclassified)))\n",
    "                    print(\"Accuracy attuale: {}%\".format((correct_predictions/total_images)*100))\n",
    "                    print(\"\")\n",
    "\n",
    "            if total_images != 0:    #Per ogni epsilon impostata salvo in accuracy plot\n",
    "                if len(perturbation) == total_images:\n",
    "                    perturbazione_media = sum(perturbation)/total_images    #Calcolo la media delle perturbazioni applicate su tutte le immagini per una determinata epsilon\n",
    "                    perturbation_for_eps[i][j] = perturbazione_media\n",
    "                    print(\"----------- Perturbazione media aggiunta a tutte le immagini per eps_Step: {} equivale a {}% ----------------\".format(eps_step[j],perturbazione_media))\n",
    "\n",
    "                final_accuracy = correct_predictions/total_images\n",
    "                accuracy_for_eps[i][j] = final_accuracy\n",
    "                print(\"----------- Accuracy sugli adversarial Sample per eps_step: {} equivale a {}% ----------------\".format(eps_step[j],final_accuracy))\n",
    "                \n",
    "                accuracy_misclassified = correct_misclassified/total_images\n",
    "                accuracy_misclassified_for_eps[i][j] = accuracy_misclassified\n",
    "                print(\"----------- Adversarial Sample misclassificati correttamente: {}% -----------\".format((accuracy_misclassified)))\n",
    "                print(\"\")\n",
    "            #Per ogni epsilon impostata salvo in accuracy plot\n",
    "        print(\"\")\n",
    "\n",
    "        print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\")\n",
    "        print(\"\")\n",
    "\n",
    "# correct_predictions = 0\n",
    "# total_images = 0\n",
    "# target_class = 10\n",
    "# print(\"ETICHETTA TARGET: \", LABELS[10])\n",
    "# batch_size = test_img.shape[0]\n",
    "# targeted_labels = np.array([target_class] * batch_size)\n",
    "# one_hot_targeted_labels = tf.keras.utils.to_categorical(targeted_labels, num_classes=8631)\n",
    "\n",
    "# for filename in os.listdir(dataset_dir):\n",
    "#     if filename.endswith(\".jpg\") or filename.endswith(\".jpeg\"):\n",
    "#         person_path = os.path.join(dataset_dir, filename)\n",
    "#         print(\"Immagine:\", filename)\n",
    "#         test_img = load_image(person_path)\n",
    "#         test_img = test_img.unsqueeze(0)\n",
    "#         test_img = test_img.numpy()\n",
    "#         test_images_adv = attack.generate(test_img, one_hot_targeted_labels)\n",
    "#         model_predictions = model.predict(test_images_adv)\n",
    "#         correct_label = re.sub(r'_\\d+_face_0\\.jpg$', '', filename)\n",
    "#         print(\"Etichetta corretta:\", correct_label)   \n",
    "#         perturbation = np.mean(np.abs((test_images_adv - test_img)))\n",
    "#         predicted_label = LABELS[np.array(model_predictions[0].argmax())]\n",
    "#         print(\"Predetto {} con probabilità {}\".format(predicted_label,model_predictions[0][model_predictions.argmax()]))\n",
    "#         total_images+=1\n",
    "\n",
    "#         if predicted_label == correct_label:\n",
    "#             correct_predictions+=1\n",
    "\n",
    "#         accuracy = correct_predictions/total_images\n",
    "#         print(\"Accuracy sugli adversarial Sample: {}%\".format((100-(accuracy*100))))\n",
    "        \n",
    "\n",
    "# if total_images != 0:\n",
    "#     final_accuracy = correct_predictions/total_images\n",
    "#     print(\"----------- Accuracy FINALE sugli adversarial Sample: {}\\% ----------------\".format(final_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# plot accuracy/Attack strength\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(np.array(eps_step), np.array(accuracy_for_eps[0]), 'b--', label='NN1')\n",
    "\n",
    "legend = ax.legend(loc='upper center', shadow=True, fontsize='large')\n",
    "legend.get_frame().set_facecolor('#00FFCC')\n",
    "\n",
    "plt.xlabel('Attack strength (eps)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot( np.array(perturbation_for_eps[0]),np.array(accuracy_for_eps[0]), 'b--', label='NN1')\n",
    "\n",
    "legend = ax.legend(loc='upper center', shadow=True, fontsize='large')\n",
    "legend.get_frame().set_facecolor('#00FFCC')\n",
    "\n",
    "plt.xlabel('Attack strength (eps)')\n",
    "plt.ylabel('mean perturbation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(np.array(eps_step),np.array(accuracy_misclassified_for_eps[0]), 'b--', label='NN1')\n",
    "\n",
    "legend = ax.legend(loc='upper center', shadow=True, fontsize='large')\n",
    "legend.get_frame().set_facecolor('#00FFCC')\n",
    "\n",
    "plt.xlabel('Attack strength (eps)')\n",
    "plt.ylabel('mean perturbation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single sample Targeted attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 1\n",
    "eps_step = 0.005\n",
    "max_iter = 5 \n",
    "\n",
    "attack = ProjectedGradientDescentPyTorch(estimator=model, eps = epsilon, eps_step= eps_step, targeted=True, max_iter = max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_image_NN1\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "target_class = 10\n",
    "\n",
    "dataset_dir = \"test_set_cropped/\"\n",
    "filename = \"Brad_Pitt_8_face_0.jpg\"\n",
    "person_path = os.path.join(dataset_dir, filename)\n",
    "\n",
    "test_img = load_image_NN1(person_path)\n",
    "target_class = 10\n",
    "etichetta_target = LABELS[0]\n",
    "print(\"ETICHETTA TARGET: \", LABELS[10])\n",
    "batch_size = test_img.shape[0]\n",
    "targeted_labels = np.array([target_class] * batch_size)\n",
    "one_hot_targeted_labels = tf.keras.utils.to_categorical(targeted_labels, num_classes=8631)\n",
    "print(one_hot_targeted_labels.shape)\n",
    "\n",
    "\n",
    "test_img_numpy = test_img.numpy()\n",
    "test_images_adv = attack.generate(test_img_numpy, one_hot_targeted_labels)\n",
    "model_predictions = model.predict(test_images_adv)\n",
    "\n",
    "\n",
    "\n",
    "model_predictions = model.predict(test_images_adv)\n",
    "perturbation = np.mean(np.abs((test_images_adv - test_img_numpy)))\n",
    "print('Average perturbation: {:4.2f}'.format(perturbation))\n",
    "#targeted_attack_loss, targeted_attack_accuracy = model.evaluate(test_images_adv, targeted_labels)\n",
    "#print('Targeted attack accuracy: {:4.2f}'.format(targeted_attack_accuracy))\n",
    "print(\"Etichetta target:{}\".format(LABELS[target_class]))\n",
    "predicted_label = LABELS[np.array(model_predictions.argmax())]\n",
    "print(\"{} con probabilità {}\".format(predicted_label,model_predictions[0][model_predictions.argmax()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepara le immagini per la visualizzazione\n",
    "# Rimuovi la dimensione batch extra e converti nel formato channels-last\n",
    "test_images_adv = np.squeeze(test_images_adv, axis=0)\n",
    "test_images_adv = np.transpose(test_images_adv, (1, 2, 0))\n",
    "\n",
    "# Converti le immagini in uint8 per la visualizzazione\n",
    "if test_img_numpy.dtype != np.uint8:\n",
    "    test_img_numpy = (test_img_numpy * 255).astype(np.uint8)\n",
    "    test_img_numpy = np.squeeze(test_img_numpy, axis=0)  # Rimuovi la dimensione batch extra\n",
    "    test_img_numpy = np.transpose(test_img_numpy, (1, 2, 0))\n",
    "\n",
    "if test_images_adv.dtype != np.uint8:\n",
    "    test_images_adv = (test_images_adv * 255).astype(np.uint8)\n",
    "\n",
    "# Visualizza le immagini affiancate con Matplotlib\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "# Mostra l'immagine originale\n",
    "ax1.imshow(test_img_numpy)\n",
    "ax1.set_title('Original Image')\n",
    "ax1.axis('off')\n",
    "\n",
    "# Mostra l'immagine avversaria\n",
    "ax2.imshow(test_images_adv)\n",
    "ax2.set_title(f'Adversarial Image\\nPredicted: {predicted_label}')\n",
    "ax2.axis('off')\n",
    "\n",
    "# Mostra la figura\n",
    "plt.suptitle(\"DeepFool Adversarial Images\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
